<!DOCTYPE HTML>
<!--
	Future Imperfect by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Open UC Hardware</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="single is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">OUCH</a></h1>
						<nav class="links">
							<ul>
								<li><a href="meta.html">Meta-Tutorial</a></li>
								<li><a href="advice.html">UC Advice Talks</a></li>
								<li><a href="index.html">UC Interviews</a></li>
							</ul>
						</nav>
						<nav class="main">
							<ul>
								<li class="search">
									<a class="fa-search" href="#search">Search</a>
									<form id="search" method="get" action="#">
										<input type="text" name="query" placeholder="Search" />
									</form>
								</li>
								<li class="menu">
									<a class="fa-bars" href="#menu">Menu</a>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Menu -->
				<section id="menu">

					<!-- Search -->
						<section>
							<form class="search" method="get" action="#">
								<input type="text" name="query" placeholder="Search" />
							</form>
						</section>

					<!-- Links -->
						<section>
							<ul class="links">
								<li>
									<a href="meta.html">
										<h3>Meta-Tutorial</h3>
										<p>Conclusions from Meta-Tutorial organized as part of ASPLOS'23, Vancouver, Canada</p>
									</a>
								</li>
								<li>
									<a href="advice.html">
										<h3>UC Advice Talks</h3>
										<p>UC Advice Talks from Open Source Hardware LatchUp conference and beyond</p>
									</a>
								</li>
								<li>
									<a href="index.html">
										<h3>UC Interviews</h3>
										<p>Interviews with UC people about Open Source Hardware and its impact</p>
									</a>
								</li>
							</ul>
						</section>

				</section>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<article class="post">
								<header>
									<div class="title">
										<h2><a href="#">Neuromorphic Computing and Open Source Hardware</a></h2>
										<p>An Interview with UC Santa Cruz Professor Jason Eshraghian</p>
									</div>
									<div class="meta">
										<time class="published" datetime="2023-04-01">April 1, 2023</time>
										<a href="parker.html" class="author"><span class="name">Parker Murray</span><img src="images/parker.jpg" alt="" /></a>
									</div>
								</header>
								<span class="image featured"><img src="images/snntorch.png" alt="" /></span>
								<p>
									Q: What future do you see, both with your work with SN Torch and analog
									computing? Kind of broad, but
									we'll give you just kind of free reign to
									go about with that. <br></br>

									A: Yeah, of course.
									Well, with spiking neural nets, the thing is
									we're trying to take principles
									from the brain and understand what
									the neuroscientists discover, and
									take all those ideas in order to
									make neural networks just a little
									bit more, or a lot more efficient.
									Right? Because we barely
									understand the brain, I'm sure different
									people have different opinions, but
									in my view, we haven't scratched the surface.
									But because we hardly
									have a sound understanding of what makes the
									brain tick,
									there is a lot of optimization
									left, right? I mean, you've got neural
									network models, chat GPT
									and whatnot, being trained
									using millions of dollars just in
									their power budgets, right? Whereas
									spiking neural network can start functioning
									based off this coffee that I'm drinking
									right now, right?
									So, we've got to figure that out. But at the same
									time, a lot of the KPIs in assessing
									how neural networks perform are
									accuracy driven, or how well does it
									classify a handwritten digit,
									which is not quite what the brain
									does, right? The brain is learning
									from an environment, so we have to come up
									with new algorithms, but these algorithms
									also have to be very well tailored to the
									hardware that they run on, right?
									With the brain, the neural code
									or what the brain does, the neural algorithm
									is just
									the neural physical
									mechanism, right? The neural hardware
									is a physical manifestation
									of some set algorithm.
									Exactly. So, that's more
									or less what we're trying to do.
									I said that my work isn't completely limited to
									analog, because at the same time, we're trying to do
									something useful as well. We are at a point
									where if we want to
									look competitive, I'm probably answering a bunch
									of future questions here as well.
									If we want to be competitive
									and if we want to show people that
									spiking neural networks do have utility,
									that they do have some scope
									in the broader deep learning landscape,
									that they can do what deep learning
									already does at a much lower cost.
									If we don't have to jump straight through
									and immediately get
									the efficiency of the brain, rather
									trying to show that
									what deep learning
									does is a very, very small subset
									of what the brain does, let's just do it more efficiently.
									In the meantime, yeah,
									I'm perfectly comfortable using digital
									hardware and whatnot to try and
									build accelerators specifically
									for SNNs, but yeah, look,
									coming up with better training
									algorithms for spiking neural nets and
									making sure that they're very suitable for both
									digital, mixed signal,
									analog hardware.
									That's it, that's the dream right now.<br></br>

									Q: This next one is
									labeled hot take.
									Do we even need to imitate the brain
									as a computational
									model, given the fact that we know
									that it has limitations, right?
									We can see there are many tasks
									that computers can do,
									at least in terms of raw
									computation, I guess, is I think the point they're getting at.
									Better than a human, right?
									It's certainly, according to the question, something beautiful and
									power efficient, but we're curious about your reasoning
									for why imitate the brain as a computational model, rather than
									bootstrapping something, which I suppose is what we're doing with deep neural networks, but I'll let
									you elaborate. <br></br>

									A: Who wrote this hot take?
									Get them to at me.
									No, no, no,
									it's a really good point because
									there are a lot of,
									there is a lot of focus out there on
									building brain models
									or building subcortical regions
									and models of them.
									And, great, models are models.
									They give you a bit of insight into what the brain
									does. What my group is
									specifically focused on is making something
									useful out of those models.
									So, unless I know why
									particular ion channels
									are giving rise to action potentials,
									unless I know the why, unless I know why
									a certain thing is the way it is,
									I will abstract it away.
									I'm not interested in it.
									I need some concrete
									evidence, or at least
									a solid
									bit of promise that
									a particular feature of the brain
									is going to give rise to
									better performance for me to waste
									many years on making it useful.
									So, yeah, the low-level
									details I typically get rid of.
									At the moment, the things that are very obvious
									to people are neurons and synapses
									are co-located. Let's do in-memory computing.
									Synapses have particular
									dynamics. Memory circuits
									and memory cells have particular dynamics if you look
									at DRAM. You turn off the refresh,
									save power on that,
									but DRAM leaks. Neurons leak.
									So there's a lot of analogs
									between the brain and
									between circuit elements that
									we can implement
									particular brain dynamics that we know
									have use naturally
									in the physics of the hardware.<br></br>

									Q: When we are
									encoding data for a spiking
									neural network, what factors
									should we consider, thinking about
									either privacy, compatibility,
									et cetera? I'm not sure that that's the direction
									that I would take that question,
									but yeah, sure. When encoding
									data for spiking neural networks, what factors
									should we consider? <br></br>

									A: So broadly, a lot of the
									work that I've done has focused
									on not encoding data for spiking neural networks.
									You let the spiking neural network do
									the encoding, but
									when you consider the sensory periphery,
									when your vision system,
									when your olfactory system, your sight,
									smell, touch, haptic feedback, et cetera,
									all of that is transmitting information
									to your brain through
									the common currency of the spike.
									Everything is spiking. Sure, sure.
									As far as we understand it, we've got
									action potentials where we don't really care about the amplitude
									of the spike, the pulse width of the spike,
									we just care for the fact that a spike
									happened
									at a particular instance in time
									or with a given frequency or a spike
									count or with a particular interval.
									So we've got these temporal encodings
									of spikes. Now,
									in terms of encoding data,
									the most useful thing that I've seen
									for encoding in the context
									of neuromorphic engineering
									is called event-based sensing.
									The best
									analogy here is
									think of a camera. We've got these
									cameras actually commercially being
									sold by groups from ETH, Zurich,
									Sony, Prophecy, a few companies
									are flogging them out there.
									Your eyes
									are constantly taking information in.
									You're not paying attention to my background,
									to this white wall, right?
									So your brain is going to pretty much,
									it's thought that the brain is going to suppress
									that information because there's nothing to process
									or there's nothing useful to be gained
									by looking at it. And so these cameras
									block static movement
									with the expectation that once it's seen it,
									perhaps there's some
									attractive dynamic or memory in your network
									that can retain whatever it deems important
									and only motion is going to be
									captured. So that type of
									encoding mechanism is not only optimized for
									power because you no longer need to process
									a bunch of pixels, but it's
									also great for security. If you
									have an always-on security camera,
									most of the time, no one's stealing anything.
									It only starts churning through
									resources once it
									needs to. So in terms of
									security, I see a lot of potential there.
									<br></br>

									Q: Fantastic. Let's see. Maybe we'll pivot
									away from your research and we've got
									some more general questions. <br></br>

									A: Oh no, I suck at being inspirational.<br></br>

									Q: Yeah, I know.
									We can talk till we're blue in the face about
									research.
									Okay, so let's see. What makes you
									want to wake up in the morning
									or stay up late at night?
									Apparently this question is from
									the Computer Architecture Podcast and
									Dr. Lisa Su. <br></br>

									Q: Oh, I do listen to that.
									I suppose it's a passion question, right?
									What makes you get up in the morning or stay up late at night
									depending on what your inclination is?
									My basic human nature.
									Damn.
									I really need to work on my social skills
									and this conversational ability.
									No, look,
									I enjoy the work I do.
									It's a very unsurprising
									characteristic of an academic answer.
									It's curiosity, right?
									I'm clearly not in it
									for the pay.
									Clearly not in it for the
									exorbitant rent that Santa Cruz charges.
									But
									within funding constraints, I get to
									work on the stuff that I find interesting.
									I mean, the prospect of
									commercialization is cool and all, but
									all of that is secondary. Getting to work with
									awesome students every day that
									teach me something new and then teaching them
									something right back.
									These tennis matches of stuff.
									That's pretty dope.<br></br>

									Q: I like it. That's a great answer.
									I think you thought on the fly well.
									Since we're at an open-source
									hardware conference, we can ask some
									general RISC-y questions.
									What do you think is
									great about RISC-V and the open-source
									hardware community?<br></br>

									A: So much.
									Not just the
									fact that
									open-source hardware and
									RISC-V as well,
									well not specifically, just generally,
									people can learn
									so much from it.
									I remember being an undergrad trying to get
									into chip design. I was at
									the University of Western Australia, which is definitely
									not known for its chip
									design infrastructure or education.
									I actually ended up spending half my PhD
									in South Korea because of it.
									But the
									fact that open-source is taking off means that
									I no longer need to spend
									three weeks Google searching
									cadence
									torrent.
									Not that I ever did.
									I didn't
									need to find virtual machines that had all these
									things pre-installed
									and PDKs.
									The fact that
									all of this is out there,
									I wish I was born
									five years later for that.
									Just so I could have a little bit of experience there.
									Waste a lot less time.
									The education is
									the coolest thing to me.
									It's so much more accessible and that's
									what I think is the most important part
									of open-sourcing.
									Of course, there's all the other benefits
									where you have community-based infrastructure
									where people are all going to help you debug,
									where people are all going to help you
									build tooling.
									In my personal
									experience, it's all just been education.
									Having everything out there,
									being able to ask anybody a question without
									pesky NDAs and that,
									without having to be an employee until
									going to Apple University, which requires
									you to understand the topic before getting
									into it.
									Education is everything.<br></br>

									Q: That's fantastic.
									What do you think the position of
									the open-source community,
									it says open-source, but I'm assuming we're talking open-source hardware,
									vis-a-vis generative
									models, generative AI?<br></br>

									A: You've got so many
									open-source language models,
									I'm assuming.
									I've got to plug myself here, actually.
									My incoming graduate student,
									he built
									what's called SpikeGPT,
									a spiking neural net for
									large language models.
									Same number of parameters as the lightweight stuff
									with 22x less
									projected energy efficiency.
									Better energy efficiency.
									All the way around.
									Very similar performance.
									Open-sourcing lets you do that kind of thing.
									It lets you iterate on everybody else's models.
									I mean, ChatGPT is
									fundamentally based on self-attention
									mechanisms, transformer blocks that
									have been written in PyTorch, open-source
									code. All of these things
									are open-source. We can see exactly
									the operations that are going on.
									Maybe not so much with GPT4.
									That's another question.
									But everything else, we've got hardware
									that can be specifically tailored.
									We can build FPGAs
									that can precisely do the operations
									that you need.
									I'm kind of curious to see how GPT4 is going to pan out
									because that is not open-source.
									On the one hand,
									I'm all for distributing the power
									of big tech conglomerates
									and that, and
									GPT4 not being open-source
									and them being very hush-hush about
									OpenAI being very hush-hush about it.
									On the one hand, it's bad.
									Can't see what's going on.
									Can't see security concerns.
									On the other hand, it means that you're not
									going to have hardware that is tailored for it.
									Does that give an opportunity
									to other open-source models
									to be accelerated
									and potentially work better than
									GPT4S models.<br></br>

									Q: Great. General fun
									questions for conclusion.<br></br>

									A: This was all fun.<br></br>

									Q: Favorite open-source license
									if you've got one.<br></br>

									A: You know what?
									I actually specialized in intellectual property.<br></br>

									Q: No kidding?<br></br>

									A: This was separate to the engineering stuff.
									And yet, I don't know.
									I've seen lawsuits
									surrounding everything.
									Pick the right one for the right job.
									What do I use?
									I actually separate it.
									I had one for the code base,
									but then I went to MIT for the documentation
									and a bunch of blood, sweat, and tears went into that.
									I felt like attribution
									was deserved on that front,
									but then everything else was a lot more permissive.
									Not that MIT is not permissive,
									but attribution is important.<br></br>

									Q: Great.
									We'll close out right on time
									with any wisdom for early-stage PhD students
									for productivity and research
									creativity and consistency.<br></br>

									A: Stay curious.
									I don't know why you're doing your PhD.
									That doesn't equate to knowing
									what you're going to do after your PhD.
									I had no idea.
									Even as a professor, I had no idea.
									Stay curious about what you're doing.
									Aim to be a couple of steps ahead of the curve.
									Knowing what gaps there are
									usually comes from doing some work,
									running into a heap of problems,
									and being like,
									go fix it.
									Fix it.
									Fix it with curiosity
									and with the intention of
									helping yourself.
									Help others. That can broaden your impact as well.
									Open sourcing is a great way to broaden your impact.
									I don't think I would have this job
									if I didn't open source S&N Torch
									and make it with the user in mind.<br></br>

									Q: Thank you so much for your time.<br></br>
									</p>
								<!-- <p>Nunc quis dui scelerisque, scelerisque urna ut, dapibus orci. Sed vitae condimentum lectus, ut imperdiet quam. Maecenas in justo ut nulla aliquam sodales vel at ligula. Sed blandit diam odio, sed fringilla lectus molestie sit amet. Praesent eu tortor viverra lorem mattis pulvinar feugiat in turpis. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Fusce ullamcorper tellus sit amet mattis dignissim. Phasellus ut metus ligula. Curabitur nec leo turpis. Ut gravida purus quis erat pretium, sed pellentesque massa elementum. Fusce vestibulum porta augue, at mattis justo. Integer sed sapien fringilla, dapibus risus id, faucibus ante. Pellentesque mattis nunc sit amet tortor pellentesque, non placerat neque viverra. </p> -->
								<footer>
									<ul class="stats">
										<li><a href="index.html">Main</a></li>
										<!-- <li><a href="#" class="icon solid fa-heart">28</a></li>
										<li><a href="#" class="icon solid fa-comment">128</a></li> -->
									</ul>
								</footer>
							</article>

					</div>

				<!-- Footer -->
					<section id="footer">
						<ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="#" class="icon solid fa-rss"><span class="label">RSS</span></a></li>
							<li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						</ul>
						<p class="copyright">&copy; Untitled. Design: <a href="http://html5up.net">HTML5 UP</a>. Images: <a href="http://unsplash.com">Unsplash</a>.</p>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
